<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>1&nbsp; Course reminders – Lab sessions : Stochastic Control and Machine Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../contents/DeepPDE/TP1.html" rel="next">
<link href="../../index.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-2486e1f0a3ee9ee1fc393803a1361cdb.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-275061990db69f1fcac8dd72fc2d8868.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../utils/styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../contents/DeepPDE/RappelsDeepPDE.html">Part n°1 : Deep Learning for PDE</a></li><li class="breadcrumb-item"><a href="../../contents/DeepPDE/RappelsDeepPDE.html"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Course reminders</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Lab sessions : Stochastic Control and Machine Learning</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/SamyMekk/TP-Controle-Stochastique" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Global informations</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Part n°1 : Deep Learning for PDE</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/DeepPDE/RappelsDeepPDE.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Course reminders</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/DeepPDE/TP1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Lab work n°1</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Part n°2 : Reinforcement Learning for stochastic control</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/RL/RappelsRL.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Course reminders</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/RL/TP2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Lab work n°2</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Part n°3 : GenAI for data generation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/GenerativeIA/TP3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Lab work n°3</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#some-reminders-on-pde-and-stochastic-control" id="toc-some-reminders-on-pde-and-stochastic-control" class="nav-link active" data-scroll-target="#some-reminders-on-pde-and-stochastic-control"><span class="header-section-number">1.1</span> Some reminders on PDE and stochastic control</a>
  <ul class="collapse">
  <li><a href="#stochastic-control-in-a-nutshell" id="toc-stochastic-control-in-a-nutshell" class="nav-link" data-scroll-target="#stochastic-control-in-a-nutshell"><span class="header-section-number">1.1.1</span> Stochastic control in a nutshell</a></li>
  <li><a href="#the-dynamic-programming-approach-hjb-equation" id="toc-the-dynamic-programming-approach-hjb-equation" class="nav-link" data-scroll-target="#the-dynamic-programming-approach-hjb-equation"><span class="header-section-number">1.1.2</span> The dynamic programming approach : HJB equation</a></li>
  <li><a href="#the-bsde-approach-pontryagins-formulation" id="toc-the-bsde-approach-pontryagins-formulation" class="nav-link" data-scroll-target="#the-bsde-approach-pontryagins-formulation"><span class="header-section-number">1.1.3</span> The BSDE approach : Pontryagin’s formulation</a></li>
  </ul></li>
  <li><a href="#neural-networks-based-algorithms-for-solving-pdes" id="toc-neural-networks-based-algorithms-for-solving-pdes" class="nav-link" data-scroll-target="#neural-networks-based-algorithms-for-solving-pdes"><span class="header-section-number">1.2</span> Neural networks based algorithms for solving PDEs</a>
  <ul class="collapse">
  <li><a href="#deep-galerkin-algorithm" id="toc-deep-galerkin-algorithm" class="nav-link" data-scroll-target="#deep-galerkin-algorithm"><span class="header-section-number">1.2.1</span> Deep Galerkin Algorithm</a></li>
  <li><a href="#deep-backward-solvers" id="toc-deep-backward-solvers" class="nav-link" data-scroll-target="#deep-backward-solvers"><span class="header-section-number">1.2.2</span> Deep Backward Solvers</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">
<div style="display:&nbsp;none;"><p style="display: none;">

$$

\newcommand{\bx}{\boldsymbol{x}}

\newcommand{\bt}{\boldsymbol{\theta}}

\newcommand{\dkl}{\mathrm{d}_{\mathrm{KL}}}

\newcommand{\dtv}{\mathrm{d}_{\mathrm{TV}}}

\newcommand{\emv}{\hat{\theta}_{\mathrm{emv}}}

\newcommand{\ent}{\mathrm{Ent}}

$$

</p></div>

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../contents/DeepPDE/RappelsDeepPDE.html">Part n°1 : Deep Learning for PDE</a></li><li class="breadcrumb-item"><a href="../../contents/DeepPDE/RappelsDeepPDE.html"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Course reminders</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Course reminders</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>The following is a reminder of the main theoretical results about <strong>Deep Learning algorithms for PDE</strong> seen during the course.</p>
<section id="some-reminders-on-pde-and-stochastic-control" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="some-reminders-on-pde-and-stochastic-control"><span class="header-section-number">1.1</span> Some reminders on PDE and stochastic control</h2>
<section id="stochastic-control-in-a-nutshell" class="level3" data-number="1.1.1">
<h3 data-number="1.1.1" class="anchored" data-anchor-id="stochastic-control-in-a-nutshell"><span class="header-section-number">1.1.1</span> Stochastic control in a nutshell</h3>
<div id="formula-description" class="formulation">
<p><span class="para-title">Mathematical setup</span></p>
<ul>
<li><span class="para-subtitle">Dynamics of the controlled state process</span></li>
</ul>
<p>Let <span class="math inline">\((\Omega,\mathcal{F}, \mathbb{F}=(\mathcal{F}_t)_{t \geq 0}, \mathbb{P})\)</span> be a probability space satisfying the usual assumptions and big enough to support for simplicity a <span class="math inline">\(\mathbb{R}^n\)</span>-valued Brownian motion <span class="math inline">\(W=(W_t)_{t \geq 0}\)</span>. We consider a control model where the state of the system is governed by a stochastic differential equation (SDE) valued in <span class="math inline">\(\mathbb{R}^n\)</span> given by</p>
<p><span id="eq-dynamics-stateprocess"><span class="math display">\[
\begin{align}
    d X_s = b(X_s,\alpha_s) d s + \sigma(X_s, \alpha_s ) d W_s, \hspace{0.5 cm}
\end{align}
\tag{1.1}\]</span></span> starting from <span class="math inline">\(X_0= x \in \mathbb{R}^n\)</span> and where we are given 2 measurable maps <span class="math inline">\((b,\sigma) : \ \mathbb{R}^n \times A \to \mathbb{R}^n ,\mathbb{R}^{n \times n}\)</span> and the control <span class="math inline">\(\alpha=(\alpha_t)_{0 \leq t \leq T}\)</span> is a progressively measurable (with respect to <span class="math inline">\(\mathbb{F})\)</span> process valued in <span class="math inline">\(A \subset \mathbb{R}^m\)</span>. We suppose that the measurable maps <span class="math inline">\((b,\sigma)\)</span> satisfy a uniform Lipschitz condition on <span class="math inline">\(A\)</span>: <span class="math inline">\(\exists K \geq 0\)</span>, <span class="math inline">\(\forall x,y \in \mathbb{R}^n\)</span>, <span class="math inline">\(\forall a \in A\)</span>, <span class="math display">\[\begin{align}
    | b(x,a) - b(y,a) |+ |\sigma(x,a) - \sigma(y,a) | \leq  K |x-y|.
\end{align}\]</span> In the sequel, for <span class="math inline">\(0 \leq t \leq T\)</span>, we denote by <span class="math inline">\(\mathcal{T}_{t,T}\)</span> the set of stopping times valued in <span class="math inline">\([t,T]\)</span>. Fix <span class="math inline">\(T &gt; 0\)</span> and we denote by <span class="math inline">\(\mathcal{A}\)</span> the set of progressively mesurable with respect to <span class="math inline">\(\mathbb{F}\)</span> control processes <span class="math inline">\(\alpha = (\alpha_t)_{0 \leq t \leq T}\)</span> such that <span class="math display">\[\begin{align}
\mathbb{E} \Big[ \int_{0}^{T} | b(0,\alpha_t)|^2 + |\sigma(0,\alpha_t)|^2 dt \Big] &lt; + \infty.
\end{align}\]</span> It is known that under the previous conditions, existence and unicity of a strong solution to the SDE (1) for any initial condtion <span class="math inline">\((t,x) \in [0,T] \in \mathbb{R}^n\)</span>. Starting from <span class="math inline">\(x\)</span> at <span class="math inline">\(s=t\)</span>, we then denote by <span class="math inline">\(\big \lbrace X_s^{t,x}, t \leq s \leq T \big \rbrace\)</span> the solution to <span class="math inline">\((1)\)</span> which admits a modification with continuous paths up to indistinguability. We also recall that under the standard conditions on <span class="math inline">\((b,\sigma)\)</span> and on the integrability condition on <span class="math inline">\(\alpha\)</span>, we have <span class="math display">\[\begin{align}
  \mathbb{E} \Big[ \underset{s \leq t \leq T}{\text{ sup }} |X_s^{t,x}|^2 \Big] &lt; \infty.
\end{align}\]</span></p>
<ul>
<li><span class="para-subtitle">Functional objective</span></li>
</ul>
<p>Let <span class="math inline">\(f :[0,T] \times \mathbb{R}^n \times A \to \mathbb{R}\)</span> and <span class="math inline">\(g : \mathbb{R}^n \to \mathbb{R}\)</span> two measurable functions. We suppose that g satisfies a quadratic growth condition : <span class="math inline">\(|g(x)| \leq C( 1+ |x|^2)\)</span>, <span class="math inline">\(\quad\)</span> <span class="math inline">\(\forall x \in \mathbb{R}^n\)</span>, for some constant <span class="math inline">\(C\)</span> independant of <span class="math inline">\(x\)</span>. For <span class="math inline">\((t,x) \in [0,T] \times \mathbb{R}^n\)</span>, we denote by <span class="math inline">\(\mathcal{A}(t,x)\)</span> the subset of controls <span class="math inline">\(\alpha \in \mathcal{A}\)</span> such that <span class="math display">\[
\begin{align}
\mathbb{E} \Big [ \int_{t}^{T} f(s,X_s^{t,x}, \alpha_s) d s \Big] &lt; \infty,
\end{align}
\]</span> and we assume that <span class="math inline">\(\mathcal{A}(t,x)\)</span> is not empty for all <span class="math inline">\((t,x) \in [0,T] \times \mathbb{R}^n\)</span>. We can then define the cost functional <span class="math display">\[
\begin{align}
J(t,x,\alpha) := \mathbb{E} \Big[ \int_{t}^{T} f(s,X_s^{t,x},\alpha_s) d s + g(X_T^{t,x}) \Big],
\end{align}
\]</span> for all <span class="math inline">\((t,x) \in [0,T] \times \mathbb{R}^n\)</span> and <span class="math inline">\(\alpha \in \mathcal{A}(t,x)\)</span>. The objective is to maximise over control processes the gain function <span class="math inline">\(J\)</span> and we introduce the value function</p>
<p><span id="eq-value-function"><span class="math display">\[
\begin{align}
v(t,x) = \underset{\alpha \in \mathcal{A}(t,x)}{\text{ sup }} J(t,x,\alpha).
\end{align}
\tag{1.2}\]</span></span></p>
<ul>
<li>Given an initial condition <span class="math inline">\((t,x) \in [0,T) \times \mathbb{R}^n\)</span>, we say that <span class="math inline">\(\hat{\alpha} \in \mathcal{A}(t,x)\)</span> is an optimal control if <span class="math inline">\(v(t,x) = J(t,x,\hat{\alpha})\)</span>.</li>
<li>A control process <span class="math inline">\(\alpha= (\alpha_s)_{t \leq s \leq T}\)</span> in the form <span class="math inline">\(\alpha_s = \mathrm{a}(s,X_s^{t,x})\)</span> for some measurable function <span class="math inline">\(\mathrm{a}\)</span> from <span class="math inline">\([0,T] \times \mathbb{R}^n\)</span> into <span class="math inline">\(A\)</span> is called Markovian control.</li>
</ul>
</div>
</section>
<section id="the-dynamic-programming-approach-hjb-equation" class="level3" data-number="1.1.2">
<h3 data-number="1.1.2" class="anchored" data-anchor-id="the-dynamic-programming-approach-hjb-equation"><span class="header-section-number">1.1.2</span> The dynamic programming approach : HJB equation</h3>
<p>The dynamic programming principle (DPP) is a fundamental principle in the theory of stochastic control. For controlled Markov processes, it is formulated as follows</p>
<div id="thm-DPPprinciple" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1.1 (Dynamic Programming Principle.)</strong></span> Let <span class="math inline">\((t,x) \in [0,T] \times \mathbb{R}^n\)</span>. Then, we have <span id="eq-dynamicprogramming"><span class="math display">\[
\begin{align}
v(t,x) &amp;= \underset{\alpha \in \mathcal{A}(t,x)}{\text{ sup }}  \mathbb{E} \Big[ \int_{t}^{t+ \theta} f(s,X_s^{t,x},\alpha_s) d s + v(\theta, X_{\theta}^{t,x}) \Big]
\end{align}
\tag{1.3}\]</span></span> for any stopping time <span class="math inline">\(\theta \in \mathcal{T}_{t,T}\)</span>.</p>
<p>The interpretation of the DPP is that the optimization problem can be split in two parts: an optimal control on the whole interval <span class="math inline">\([t,T]\)</span> may be obtained by first searching for an optimal control from time <span class="math inline">\(\theta\)</span> given the state value <span class="math inline">\(X_{\theta}^{t,x}\)</span>, i.e.&nbsp;compute <span class="math inline">\(v(\theta,X_{\theta}^{t,x})\)</span> and then maximizing over controls on <span class="math inline">\([t,\theta]\)</span> the quantity</p>
<p><span class="math display">\[\mathbb{E} \Big[ \int_{t}^{\theta} f(s,X_s^{t,x},\alpha_s ) d s + v(\theta, X_{\theta}^{t,x}) \Big].\]</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof of this result is non trivial and is based on a measurable selection argument but the proof can be found easily online so we omit it for now.</p>
</div>
<div id="alg-description" class="algorithm">
<ul>
<li><span class="para-subtitle">Intuitive derivation of the HJB equation</span></li>
</ul>
<p>The Hamilton-Jacobi Bellman (HJB) equation is the infinitesimal version of the <strong>dynamic programming principle</strong>, i.e., it describes the local behavior of the value function when we send the stopping time <span class="math inline">\(\theta\)</span> in <a href="#eq-dynamicprogramming" class="quarto-xref">Equation&nbsp;<span>1.3</span></a> in <a href="#thm-DPPprinciple" class="quarto-xref">Theorem&nbsp;<span>1.1</span></a> to <span class="math inline">\(t\)</span>. The HJB equation is also called <strong>dynamic programming equation</strong>.</p>
<p>Let us consider the time <span class="math inline">\(\theta = t+h\)</span> and a constant control <span class="math inline">\(\alpha = (\alpha_t)_{t  \leq s \leq T}= a\)</span> for some arbitrary <span class="math inline">\(a \in A\)</span>. Therefore, from the relation <a href="#eq-dynamicprogramming" class="quarto-xref">Equation&nbsp;<span>1.3</span></a>, we have</p>
<p><span id="eq-inequality-dynamicprog"><span class="math display">\[
\begin{align}
v(t,x) \geq \mathbb{E} \Big[ \int_{t}^{t+h} f(s,X_s^{t,x},a) + v(t+h,X_{t+h}^{t,x}) \Big]
\end{align}
\tag{1.4}\]</span></span></p>
<p>Under some regularity conditions on <span class="math inline">\(v\)</span>, we may apply Itô’s formula between <span class="math inline">\(t\)</span> and <span class="math inline">\(t+h\)</span> which gives</p>
<p><span class="math display">\[
\begin{align}
v(t+h, X_{t+h}^{t,x}) = v(t,x) + \int_{t}^{t+h} \Big( \partial_t v + \mathcal{L}^a v \Big)(s, X_s^{t,x}) d s + \text{ Local martingale },
\end{align}
\]</span> where we denote the operator <span class="math inline">\(\mathcal{L}^a\)</span> associated to the diffusion with control process given by constant control <span class="math inline">\(a\)</span> and defined as <span class="math display">\[
\begin{align}
\mathcal{L}^{a}v(t,x) = b(x,a) \cdot D_x v(t,x) + \frac{1}{2} \sigma \sigma^{\top}(t,x) : D_x^2 v(t,x)
\end{align},
\]</span> where <span class="math inline">\(\cdot\)</span> denotes the scalar product between vectors on <span class="math inline">\(\mathbb{R}^n\)</span> and <span class="math inline">\(:\)</span> denotes the scalar prodcutes between matrix, i.e., <span class="math inline">\(A:B= \text{Tr}(A^{\top} B)\)</span>. Substituting into <a href="#eq-inequality-dynamicprog" class="quarto-xref">Equation&nbsp;<span>1.4</span></a>, we get <span class="math display">\[
\begin{align}
0 \geq \mathbb{E} \Big[\int_{t}^{t+h} \Big( \partial_t v+ \mathcal{L}^a v \Big)(s,X_s^{t,x} ) + f(s,X_s^{t,x},a) d s \Big]
\end{align}
\]</span> Dividing by <span class="math inline">\(h\)</span> and sending <span class="math inline">\(h \to 0\)</span>, from the continuity of the map inside the expectation, we get by the mean-value theorem</p>
<p><span id="eq-inequality-dynamicprog2"><span class="math display">\[
\begin{align}
0 \geq \partial_t v (t,x) + \mathcal{L}^a v(t,x) + f(t,x,a).
\end{align}
\tag{1.5}\]</span></span></p>
<p>Since <a href="#eq-inequality-dynamicprog2" class="quarto-xref">Equation&nbsp;<span>1.6</span></a> holds for any <span class="math inline">\(a \in A\)</span>, we obtain the inequality</p>
<p><span id="eq-inequality-dynamicprog2"><span class="math display">\[
\begin{align}
0 \geq \partial_t v (t,x) + \underset{a \in A}{\text{ sup }} \big[ \mathcal{L}^a v(t,x) + f(t,x,a) \big]
\end{align}
\tag{1.6}\]</span></span> On the other hand, if we assume that <span class="math inline">\(\alpha^{\star}= (\alpha^{\star}_t)_{0 \leq t \leq T}\)</span> is an optimal control. Then in <a href="#eq-dynamicprogramming" class="quarto-xref">Equation&nbsp;<span>1.3</span></a> , we have</p>
<p><span class="math display">\[
\begin{align}
v(t,x) = \mathbb{E} \Big[ \int_{t}^{t+h} f(s,X_s^{\star}, \alpha_s^{\star}) d s + v(t+h, X_{t+h}^{\star}) \Big],
\end{align}
\]</span> where <span class="math inline">\(X^{\star}\)</span> is the state process solution to <a href="#eq-dynamics-stateprocess" class="quarto-xref">Equation&nbsp;<span>1.1</span></a> starting from <span class="math inline">\(x\)</span> at <span class="math inline">\(t\)</span>, with the control <span class="math inline">\(\alpha^{\star}\)</span>. Using similar arguments as derived above, we end up with</p>
<p><span class="math display">\[
\begin{align}
\partial_t v(t,x) + \mathcal{L}^{\alpha^{\star}_t} v(t,x) + f(t,x, \alpha_t^{\star}) =0,
\end{align}
\]</span> which combined with <a href="#eq-inequality-dynamicprog2" class="quarto-xref">Equation&nbsp;<span>1.6</span></a>, suggests that <span class="math inline">\(v\)</span> should satisfy</p>
<p><span id="eq-PDE-dynamicprog"><span class="math display">\[
\begin{align}
\partial_t v(t,x) + \underset{a \in A}{\text{ sup }} \big[ \mathcal{L}^{a} v(t,x) + f(t,x,a) \big ] =0 , \quad \forall (t,x) \in [0,T) \times n,
\end{align}
\tag{1.7}\]</span></span> if the above supremum is finite. The PDE <a href="#eq-PDE-dynamicprog" class="quarto-xref">Equation&nbsp;<span>1.7</span></a> is often rewritten in the form</p>
<p><span id="eq-PDE-dynamicprog2"><span class="math display">\[
\begin{align}
\partial_t v(t,x) + H \big(t,x, D_x v(t,x) , D^2_x (t,x) \big) = 0, \quad \forall (t,x) \in [0,T) \times \mathbb{R}^n,
\end{align}
\tag{1.8}\]</span></span> where for <span class="math inline">\((t,x,p,M) \in [0,T] \times \mathbb{R}^n \times \mathbb{R}^n \times \mathcal{S}_n\)</span>,<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> we denote</p>
<p><span class="math display">\[
\begin{align}
H(t,x,p,M) = \underset{a \in A}{\text{ sup }} \big[ b(x,a) \cdot p + \frac{1}{2} \sigma \sigma^{\top}(x,a) : M + f(t,x,a)  \big].
\end{align}
\]</span> The map <span class="math inline">\(H\)</span> is called the Hamiltonian of the associated control problem and <a href="#eq-PDE-dynamicprog2" class="quarto-xref">Equation&nbsp;<span>1.8</span></a> is called dynamic programming equation (DPP) equation or Hamilton-Jacobi-Bellman (HJB) equation. The terminal condition to this PDE is given by</p>
<p><span class="math display">\[
\begin{align}
v(T,x) = g(x), \quad \forall x \in \mathbb{R}^n,
\end{align}
\]</span> which is an immediate consequence of the definition of the value function.</p>
</div>
<div id="alg-description" class="algorithm">
<p><span class="para-subtitle">Some remarks: </span></p>
<ul>
<li>When the control space <span class="math inline">\(A\)</span> is a singleton, i.e., <span class="math inline">\(A= \big \lbrace a_0 \rbrace\)</span>, the HJB equation is reduced to the Cauchy problem</li>
</ul>
<p><span class="math display">\[
\begin{align}
\begin{cases}
\partial_t v(t,x) + \mathcal{L}^{a_0} v(t,x) &amp;=  f(t,x,a_0), \quad \forall (t,x) \in [0,T) \times \mathbb{R}^n. \\
v(T,x) &amp;= g(x), \quad \forall x \in \mathbb{R}^n.
\end{cases}
\end{align}
\]</span></p>
<ul>
<li>The optimality argument of the DPP suggests that if one can find a measurable map $ [0,T] ^n (t,x) ^{}(t,x) A$ such that</li>
</ul>
<p><span class="math display">\[
\begin{align}
\underset{a \in A}{\text{ sup }} \big[ \mathcal{L}^a v(t,x) + f(t,x,a) \big] = \mathcal{L}^{\alpha^{\star}(t,x)} v(t,x) + f(t,x, \alpha^{\star}(t,x)),
\end{align}
\]</span> then we would get <span class="math display">\[
\begin{align}
\begin{cases}
\partial_t v(t,x) +  \mathcal{L}^{\alpha^{\star}(t,x)} v(t,x) +  f(t,x, \alpha^{\star}(t,x)) &amp;=0, \quad \forall (t,x) \in [0,T) \in \mathbb{R}^n \\
v(T,x) &amp;= g(x), \quad x \in \mathbb{R}^n
\end{cases}
\end{align}
\]</span> and so by Feynmann-Kac formula,</p>
<p><span class="math display">\[
\begin{align}
v(t,x) = \mathbb{E} \Big[ \int_{t}^{T} f(s,X_s, \alpha^{\star}(s,X_s)) d s  + g(X_T^{\star}) \Big],
\end{align}
\]</span> where <span class="math inline">\(X^{\star} = (X^{\star}_s)_{t \leq s \leq T}\)</span> is solution to the SDE $$ <span class="math display">\[\begin{align}
\begin{cases}
dX_s^{\star} &amp;= b(X_s^{\star}, \alpha^{\star}(s,X_s^{\star})) + \sigma(X_s^{\star}, \alpha^{\star}(s,X_s^{\star})) d W_s , \quad t \leq s \leq T, \\
X_t^{\star} &amp;= x
\end{cases}
\end{align}\]</span> This will show that the process <span class="math inline">\((\alpha^{\star}_s)_{t \leq s \leq T}= \big(\alpha^{\star}(s,X_s^{\star} )\big)_{t \leq s \leq T}\)</span> is an optimal Markovian control, i.e given from a measurable feedback map <span class="math inline">\(\alpha^{\star}\)</span>. <a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
</div>
<p>The crucial step in the classical approach to dynamic programming consists in proving, that given a smooth solution to the HJB equation, this candidate coïncides with the value function. This result is called <strong>verification theorem</strong>. We formulate a general version of the verification theorem.</p>
<div id="thm-verificationtheorem" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1.2 (Verification theorem.)</strong></span> Let <span class="math inline">\(w\)</span> be a function in <span class="math inline">\(\mathcal{C}^{1,2}([0,T) \times \mathbb{R}^n \cap \mathcal{C}^0([0,T] \times \mathbb{R}^n)\)</span>, satisfying a growth quadratic growth condition, i.e., there exists a constant <span class="math inline">\(C \geq 0\)</span> such that</p>
<p><span class="math display">\[
\begin{align}
|w(t,x)| \leq C \big( 1+ |x|^2 \big), \quad \forall (t,x) \in [0,T] \times \mathbb{R}^n.
\end{align}
\]</span></p>
<ul>
<li>Suppose that</li>
</ul>
<p><span class="math display">\[
\begin{align}
\begin{cases}
\partial_t w + \underset{a \in A}{\text{ sup }} \big[ \mathcal{L}^a w(t,x) + f(t,x,a) \big] &amp;\leq 0, \quad (t,x) \in [0,T) \times \mathbb{R}^n, \\
w(T,x) &amp;\geq g(x), \quad x \in \mathbb{R}^n.
\end{cases}
\end{align}
\]</span> Then <span class="math inline">\(w \geq v\)</span> on <span class="math inline">\([0,T] \times \mathbb{R}^n\)</span>.</p>
<ul>
<li>Suppose further <span class="math inline">\(w(T,\cdot)=g\)</span> and there exists a measurable map <span class="math inline">\([0,T] \times \mathbb{R}^n \ni (t,x) \mapsto \hat{\alpha}(t,x) \in A\)</span> such that <span class="math display">\[
\begin{align}
\partial_t w + \underset{a \in A}{\text{ sup }} \big[ \mathcal{L}^a w(t,x) + f(t,x,a) \big] = \partial_t w  \big[ \mathcal{L}^{\hat{\alpha}(t,x)} w(t,x) + f(t,x,\hat{\alpha}(t,x)) \big],
\end{align}
\]</span> and the SDE given by <span class="math display">\[
d X_s = b(X_s, \hat{\alpha}(s,X_s)) d s + \sigma(X_s, \hat{\alpha}(s,X_s)) d W_s,
\]</span> admits a unique solution, denoted by <span class="math inline">\(\hat{X}_s^{t,x}\)</span> and the process <span class="math inline">\(\big(\hat{\alpha}(s,X_s^{t,x}) \big)_{t \leq s \leq T} \in \mathcal{A}(t,x)\)</span>. Then, we have <span class="math inline">\(w=v\)</span> on <span class="math inline">\([0,T] \times \mathbb{R}^n\)</span> and <span class="math inline">\(\hat{\alpha}\)</span> is an optimal Markovian control.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></li>
</ul>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof of this result follow essentially from Itô’s formula after denoting the sequence of stopping times <span class="math inline">\(\tau_n = \text{inf} \lbrace s \geq t : \int_{t}^s D_x w(l, X_l^{t,x})^{\top} \sigma(X_l^{t,x}, \alpha_l)|^2 d l \geq n \big \rbrace\)</span> and noticing that <span class="math inline">\(\tau_n \nearrow \infty\)</span> as <span class="math inline">\(n\)</span> tends to <span class="math inline">\(\infty\)</span> and applying Itô’s formula to <span class="math inline">\(w\)</span> between <span class="math inline">\(t\)</span> and <span class="math inline">\(s \wedge \tau_n\)</span>.</p>
</div>
</section>
<section id="the-bsde-approach-pontryagins-formulation" class="level3" data-number="1.1.3">
<h3 data-number="1.1.3" class="anchored" data-anchor-id="the-bsde-approach-pontryagins-formulation"><span class="header-section-number">1.1.3</span> The BSDE approach : Pontryagin’s formulation</h3>
<div id="formula-description" class="formulation">
<p>We denote by <span class="math inline">\(\mathbb{S}^2([0,T];\mathbb{R})\)</span> the set of <span class="math inline">\(\mathbb{R}\)</span>-valued progressively measurables processes <span class="math inline">\(Y=(Y_t)_{0 \leq t \leq T}\)</span> such that <span class="math inline">\(\mathbb{E} \Big[ \underset{0 \leq t \leq T}{\text{ sup }} |Y_t|^2 \Big] &lt;  \infty\)</span> and by <span class="math inline">\(\mathbb{H}^2([0,T];\mathbb{R}^n)\)</span> the set of <span class="math inline">\(\mathbb{R}^n\)</span>-valued progressively measurable <span class="math inline">\(Z=(Z_t)_{0 \leq t \leq T}\)</span> such that <span class="math inline">\(\mathbb{E} \Big[ \int_{0}^{T} |Z_t|^2 d t \Big] &lt; \infty\)</span>. We are given a pair <span class="math inline">\((\xi, f)\)</span> called terminal condition and generator (or driver) satisfying :</p>
<ul>
<li><span class="math inline">\((A)\)</span> <span class="math inline">\(\xi \in L^2(\Omega;\mathcal{F}_T; \mathbb{P}; \mathbb{R})\)</span></li>
<li><span class="math inline">\((B)\)</span> <span class="math inline">\(f : \Omega \times [0,T] \times \mathbb{R} \times \mathbb{R}^d \to \mathbb{R}\)</span> such that
<ul>
<li><span class="math inline">\(f(\cdot,t,y,z)\)</span> (written for simplicity <span class="math inline">\(f(t,y,z)\)</span>) is progressively measurable for all <span class="math inline">\((y,z)\)</span></li>
<li><span class="math inline">\(f(t,0,0) \in \mathbb{H}^2([0,T];\mathbb{R})\)</span>.</li>
<li><span class="math inline">\(f\)</span> satisfies a uniform Lipschitz condition in <span class="math inline">\((y,z)\)</span>, i.e, there exists a constant <span class="math inline">\(C_f\)</span> such that <span class="math display">\[
\begin{align}
| f(t,y_1,z_1) - f(t,y_2,z_2)| \leq C_f \big ( |y_1 - y_2| + |z_1 - z_2| \big), \quad \forall y_1,y_2, \forall z_1, z_2, \quad d t \otimes d \mathbb{P} \text{ a-e.}
\end{align}
\]</span> We now consider the (unidimensional) backward stochastic differential equation (BSDE) <span id="eq-BSDE-differential"><span class="math display">\[
\begin{align}
\begin{cases}
dY_t &amp;= - f(t,Y_t,Z_t) d t + Z_t d W_t ,\\
Y_T &amp;= \xi
\end{cases}
\end{align}
\tag{1.9}\]</span></span></li>
</ul></li>
</ul>
</div>
<div id="def-solBSDE" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1.1</strong></span> A solution to the BSDE <a href="#eq-BSDE-differential" class="quarto-xref">Equation&nbsp;<span>1.9</span></a> is a pair of processes <span class="math inline">\((Y,Z) \in \mathbb{S}^2([0,T];\mathbb{R}) \times \mathbb{H}^2([0,T]; \mathbb{R}^n)\)</span> satisfying <span class="math display">\[
\begin{align}
Y_t = \xi + \int_{t}^{T} f(s,Y_s,Z_s) ds - \int_{t}^{T} Z_s d W_s, \quad 0 \leq t \leq T, \quad \mathbb{P - }\text{ a.s}. \notag
\end{align}
\]</span></p>
</div>
<p>We now state an import result ensuring existence and unicity to the BSDE <span class="math inline">\((1)\)</span></p>
<div id="thm-ExistenceUnicityBSDE" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1.3</strong></span> Given a pair of <span class="math inline">\((\xi,f)\)</span> satisfying Assumptions <span class="math inline">\((A)\)</span> and <span class="math inline">\((B)\)</span>, there exists a unique solution <span class="math inline">\((Y,Z) \in \mathbb{S}^2([0,T];\mathbb{R}) \times \mathbb{H}^2([0,T];\mathbb{R}^n)\)</span> to <a href="#def-solBSDE" class="quarto-xref">Definition&nbsp;<span>1.1</span></a>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof of <a href="#thm-ExistenceUnicityBSDE" class="quarto-xref">Theorem&nbsp;<span>1.3</span></a> is based on a fixed point argument on the Banach space <span class="math inline">\(\mathbb{S}^2([0,T];\mathbb{R}) \times \mathbb{H}^2([0,T];\mathbb{R}^n)\)</span> endowed with the norm <span class="math display">\[
\begin{align}
\lVert (Y,Z) \rVert_{\beta} = \bigg(\mathbb{E} \Big[ \int_{0}^{T}  e^{\beta s} \big( |Y_s|^2 + |Z_s|^2 \big) \Big] \bigg)^{\frac{1}{2}}
\end{align}
\]</span>. We now show that for a suitable choice of <span class="math inline">\(\beta\)</span>, the mapping <span class="math inline">\(\Phi\)</span> is well defined on <span class="math inline">\(\mathbb{S}^2([0,T];\mathbb{R}) \times \mathbb{H}^2([0,T];\mathbb{R}^n)\)</span> into <span class="math inline">\(\mathbb{S}^2([0,T];\mathbb{R}) \times \mathbb{H}^2([0,T];\mathbb{R}^n)\)</span> as <span class="math inline">\((Y,Z) = \Phi(U,V)\)</span>. Formally, defining the martingale process <span class="math inline">\(M=(M_t)_{0 \leq t \leq T}\)</span> as <span class="math inline">\(M_t = \mathbb{E} \Big[ \xi + \int_{0}^{T} f(s,U_s,V_s)| \mathcal{F}_t \Big]\)</span>, from the Itô’s martingale decomposition theorem, we got the existence of a process <span class="math inline">\(Z=(Z_t)_{0 \leq t \leq T} \in \mathbb{H}^2([0,T];\mathbb{R}^n)\)</span> such that <span class="math display">\[
\begin{align}
M_t = M_0 + \int_{0}^{t} Z_s d W_s.
\end{align}
\]</span> We then define the process <span class="math inline">\(Y=(Y_t)_{0 \leq t \leq T}\)</span> as <span class="math display">\[
\begin{align}
Y_t = M_t - \int_{0}^{t} f(s,U_s, V_s) d s .
\end{align}
\]</span> It is easy to see that <span class="math inline">\(Y_T = \xi\)</span> by construction and that our <span class="math inline">\(Y\)</span> candidate satisfies <span class="math inline">\((1)\)</span>. Now, you can check under the assumptions on <span class="math inline">\(f\)</span> and <span class="math inline">\(\xi\)</span> that <span class="math display">\[
\begin{align}
\mathbb{E} \Big[ \underset{0 \leq t \leq T}{\text{ sup }} |\int_{t}^{T} Z_s d W_s |^2 \Big] \leq 4 \mathbb{E}\Big[ \int_{0}^{T} |Z_s|^2 d s  \Big] &lt; + \infty.
\end{align}
\]</span> where the inequality follows from Doob’s inequality. Therefore, <span class="math inline">\(\Phi\)</span> is a well defined map. Now, you can check that for <span class="math inline">\(\beta\)</span> small enough, <span class="math inline">\(\Phi\)</span> is a contraction and therefore the Banach fixed point ensures that there exists a unique solution to <span class="math inline">\((1)\)</span>.</p>
</div>
<div id="alg-description" class="algorithm">
<p><span class="para-title">BSDE, PDE and nonlinear Feynman-Kac formula</span></p>
<p>In this chapter, we will study an extension of the Feynman-Kac formula for <strong>semi-linear PDE</strong> in the form <span id="eq-semilinearPDE"><span class="math display">\[
\begin{align}
\begin{cases}
\partial_t v(t,x) + \mathcal{L}v(t,x) + f(t,x,v(t,x), \sigma(t,x)^{\top} D_x v(t,x)) = 0, \quad (t,x) \in [0,T) \times \mathbb{R}^n, \\
v(T,x) = g(x).
\end{cases}
\end{align}
\tag{1.10}\]</span></span> In fact, we will represent the PDE solution of <a href="#eq-semilinearPDE" class="quarto-xref">Equation&nbsp;<span>1.10</span></a> through a suitable BSDE representation as below</p>
<p><span id="eq-BSDE-differential-2"><span class="math display">\[
\begin{align}
\begin{cases}
    d Y_s &amp;= - f(s,X_s,Y_s,Z_s) d s + Z_s d W_s , \\
    Y_T &amp;= g(X_T),
\end{cases}
\end{align}
\tag{1.11}\]</span></span> and we recall that the forward SDE <span class="math inline">\(\mathbb{R}^n\)</span>-valued process <span class="math inline">\(X=(X_t)_{0 \leq t \leq T}\)</span> is given by <span class="math display">\[
\begin{align}
d X_s = b(s,X_s) d s + \sigma(s,X_s) d W_s
\end{align}
\]</span> <span class="para-subtitle">Proposition : Link between <span class="math inline">\(v\)</span> and <span class="math inline">\((Y,Z)\)</span> :</span></p>
<p>Let <span class="math inline">\(v \in \mathcal{C}^{1,2}([0,T) \times \mathbb{R}^n) \cap C^0([0,T] \times \mathbb{R}^n)\)</span> be a solution to the PDE <span class="math inline">\((4)\)</span>, satisfying a linear growth condition and such that there exists positive constants <span class="math inline">\(C,q\)</span> such that <span class="math inline">\(| D_x v(t,x)| \leq C( 1+ |x|^q)\)</span> for any <span class="math inline">\(x \in \mathbb{R}^n\)</span>. Then the pair of processes <span class="math inline">\((Y,Z)\)</span> defined by</p>
<div class="eq-frame">
<p><span id="eq-representationYZ"><span class="math display">\[
\begin{align}
\begin{cases}
Y_t &amp;= v(t,X_t), \\
Z_t &amp;= \sigma^{\top}(X_t) D_x v(t,X_t), \quad 0 \leq t \leq T
\end{cases}
\end{align}
\tag{1.12}\]</span></span></p>
</div>
<p>is the solution to the BSDE <a href="#eq-BSDE-differential-2" class="quarto-xref">Equation&nbsp;<span>1.11</span></a>.</p>
<p><strong>Proof.</strong> This result is an immediate application of the Itô’s formula applied to the process <span class="math inline">\(\big(v(t,X_t)\big)_{0 \leq t \leq T}\)</span> and the fact that <span class="math inline">\(v\)</span> is a solution to the PDE in <a href="#eq-semilinearPDE" class="quarto-xref">Equation&nbsp;<span>1.10</span></a>. Indeed, applying Itô’s formula between <span class="math inline">\(t\)</span> and <span class="math inline">\(T\)</span>, we have <span class="math display">\[
\begin{align}
   v(t,X_t)= v(T,X_T) - \int_{t}^{T} \Big( \partial_t v(s,X_s) - \mathcal{L}v(s,X_s)  \Big) d s - \int_{t}^{T} \sigma^{\top}(s,X_s) D_x v(s,X_s) d W_s, \quad 0 \leq t \leq T.
\end{align}
\]</span> Now, using that <span class="math inline">\(v\)</span> is a solution to the PDE, we get that <span class="math display">\[
\begin{align}
Y_t = g(X_T) + \int_{t}^{T} f(s,X_s,Y_s,Z_s) d s - \int_{t}^{T} Z_s d W_s,  \quad 0 \leq t \leq T,
\end{align}
\]</span> where we set <span class="math inline">\((Y_t,Z_t) = \Big(v(t,X_t), \sigma^{\top}(t,X_t)D_x v(t,X_t)\Big)\)</span> for any <span class="math inline">\(t \in [0,T]\)</span>. Moreover, from the growth assumptions on <span class="math inline">\(v\)</span> and <span class="math inline">\(D_x v\)</span>, we get that <span class="math inline">\((Y,Z)\)</span> lies in <span class="math inline">\(\mathbb{S}^2([0,T]; \mathbb{R}) \times \mathbb{H}^2([0,T]; \mathbb{R}^n)\)</span> and is unique by <a href="#thm-ExistenceUnicityBSDE" class="quarto-xref">Theorem&nbsp;<span>1.3</span></a> .</p>
</div>
</section>
</section>
<section id="neural-networks-based-algorithms-for-solving-pdes" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="neural-networks-based-algorithms-for-solving-pdes"><span class="header-section-number">1.2</span> Neural networks based algorithms for solving PDEs</h2>
<p>Now, that we have shown how stochastic control problems naturally lead to PDEs, we will rely on some recent advances which appear to numerically solve these PDE, i.e to characterize the function and/or its derivative solution the PDE. Formally, we are going to tackle the following kind of problems.</p>
<div id="alg-description" class="algorithm">
<p><span class="para-title">PDE formulation</span></p>
<p>Let <span class="math inline">\(v\)</span> a function defined on <span class="math inline">\([0,T] \times \mathbb{R}^n\)</span> supposed to satisfy the following PDE <span id="eq-pde-formulation-algo"><span class="math display">\[
\begin{align}
\begin{cases}
\partial_t v(t,x) + \mathcal{H}[v](t,x) &amp;= 0, \quad (t,x) \in [0,T) \times \mathbb{R}^n,  \\
v(T,x) &amp;= g(x).
\end{cases}
\end{align}
\tag{1.13}\]</span></span> where the operator <span class="math inline">\(\mathcal{H}\)</span> is defined over the space of functions over <span class="math inline">\([0,T] \times \mathbb{R}^n\)</span> potentially with some regularity <span class="math inline">\([0,T] \times \mathbb{R}^n\)</span> and can be rewritten in the case we are going to cover as <span class="math display">\[\begin{align}
\mathcal{H}[v](t,x) = H \big(t,x,v(t,x), D_x v(t,x), D^2_x v(t,x) \big). \quad (2)
\end{align}\]</span> The complexity of such systems comes notably from</p>
<ul>
<li>The non linearity of <span class="math inline">\(H\)</span> with respect to <span class="math inline">\(v\)</span> and its derivatives.</li>
<li>The potentially high dimension of the underlying space (<span class="math inline">\(n \approx 100\)</span>).</li>
</ul>
<p><span class="para-subtitle">Example of PDEs.</span></p>
<ul>
<li><span class="para-subsubtitle">Linear PDE : </span></li>
</ul>
<p><span class="math display">\[\begin{align}
\begin{cases}
  \partial_t v(t,x) - r(x) v(t,x) + b(x) \cdot D_x v + \frac{1}{2} (\sigma \sigma^{\top})(t,x) : D^2_x v(t,x) + f(x)= 0, \quad (t,x) \in [0,T) \times \mathbb{R}^n \\
  v(T,x) = g(x), \quad x \in \mathbb{R}^n
\end{cases}
\end{align}\]</span> In this case, the operator <span class="math inline">\(\mathcal{H}\)</span> is linear with respect to its arguments with the map <span class="math inline">\(H\)</span> (recall <span class="math inline">\((1)\)</span>) given by <span class="math display">\[\begin{align}
H(t,x,y,z,\gamma):= -r(x) y(t,x) + b(x) \cdot z(t,x) + \frac{1}{2} (\sigma \sigma^{\top})(t,x) : \gamma(t,x)
\end{align}\]</span> This is typically the type of <span class="math inline">\(PDE\)</span> which arises in option pricing in B-S model by taking <span class="math inline">\(b=r\)</span>, <span class="math inline">\(\sigma\)</span> the volatility, <span class="math inline">\(f=0\)</span> and <span class="math inline">\(g\)</span> the option payoff.</p>
<ul>
<li><span class="para-subsubtitle">Quasilinear PDE : </span> <span class="math display">\[\begin{align}
\begin{cases}
\partial_t v + \mathcal{H}[v] + f(x,v)= 0, \quad (t,x) \in [0,T) \times \mathbb{R}^n, \quad (2)\\
v(T,x) = g(x), \quad x \in \mathbb{R}^n
\end{cases}
\end{align}\]</span> For instance, when <span class="math inline">\(f(x,y) = r \text{max}(y,0) - ry\)</span>, this is the type of PDE which arises from pricing of CVA (Credit Valuation adjustment) where <span class="math inline">\(r\)</span> denotes the intensity of default of a counterparty.</li>
</ul>
<p><span class="para-subtitle">Numerical challenges</span></p>
<p>However, solving these PDEs have always been highly challenging due to the curse of dimensionnality due to the exponentially scaling when discretizing the action mesh size <span class="math inline">\(\mathbb{R}^n\)</span> (grid based methods) but also from the point of view of Monte-Carlo methods which are limited to low dimensional setting <span class="math inline">\(n \approx 6\)</span> and where the solution is essentially computed at a fixed point <span class="math inline">\((t,x) \in [0,T] \times \mathbb{R}^n\)</span>. In order to solve <span class="math inline">\((1)\)</span> efficiently, we will rely on neural-network based algorithms which can provide a functional representation of the map <span class="math inline">\((t,x) \in [0,T] \times \mathbb{R}^n\)</span> at any <span class="math inline">\((t,x)\)</span> and for <span class="math inline">\(n\)</span> beeing large.</p>
</div>
<section id="deep-galerkin-algorithm" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="deep-galerkin-algorithm"><span class="header-section-number">1.2.1</span> Deep Galerkin Algorithm</h3>
<div id="method-description" class="methodology">
<p><span class="para-subtitle">Mathematical description : </span></p>
<p>The main idea of <strong>Deep Galerkin algorithm</strong> is to rewrite the PDE <a href="#eq-pde-formulation-algo" class="quarto-xref">Equation&nbsp;<span>1.13</span></a> via a stochastic optimization problem. Given a smooth function <span class="math inline">\(w\)</span> on <span class="math inline">\([0,T] \times \mathbb{R}^n\)</span>, we define <span id="eq-optimization-control-problem-deep-galerkin"><span class="math display">\[
\begin{align}
\mathbb{L}(w) = \mathbb{E} \Big[ w(T,\mathcal{X}) - g(\mathcal{X})|^2 \Big] + \mathbb{E} \Big[ | \partial_t w(\tau,\mathcal{X} - \mathcal{H}[w](\tau,\mathcal{X})) |^2 \Big],
\end{align}
\tag{1.14}\]</span></span> where <span class="math inline">\((\tau,\mathcal{X}) \sim \rho_T \otimes \rho_n\)</span> laws supported on $[0,T] ^n $. In order to solve <a href="#eq-optimization-control-problem-deep-galerkin" class="quarto-xref">Equation&nbsp;<span>1.14</span></a> , we parametrize the family of maps <span class="math inline">\(w\)</span> by neural networks and reduce the infinite dimensional optimization problem into a finite one where the finite parameter is given by the parameter of the neural net <span class="math inline">\(\mathcal{U}(\theta)\)</span>. and the problem is therefore now to solve <span class="math inline">\(\underset{\theta \in \Theta}{\text{ inf }} L(\theta)\)</span> with <span class="math inline">\(L(\theta)=\mathbb{L}(U_{\theta})\)</span> by uses of stochastic gradient descent methods.</p>
</div>
</section>
<section id="deep-backward-solvers" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="deep-backward-solvers"><span class="header-section-number">1.2.2</span> Deep Backward Solvers</h3>
<div id="method-description" class="methodology">
<p><span class="para-subtitle">Mathematical description of Deep BSDE Solver : </span></p>
<p>The <strong>Deep BSDE Solver</strong> takes advantages of semi-linear PDE. The idea is to approximate the unknown functions <span class="math inline">\(Y_0= v(0,X_0)\)</span> and <span class="math inline">\(Z_t = D_x v(t,X_t)\)</span> by neural networks <span class="math inline">\(\mathcal{U}_{\theta}\)</span> on $^d and <span class="math inline">\(\mathcal{Z}_{\theta}\)</span> on <span class="math inline">\([0,T] \times \mathbb{R}^d\)</span>. In practice, we will compute by minimizing over <span class="math inline">\(\theta \in \Theta\)</span> the cost function given by</p>
<p><span class="math display">\[
\begin{align}
L(\theta) = \mathbb{E} \Big[ |Y_T^{\theta} - g(X_T)|^2 \Big],
\end{align}
\]</span> where the dynamics of <span class="math inline">\((Y_t^{\theta})_{0 \leq t \leq T}\)</span> is given by</p>
<p><span class="math display">\[
\begin{align}
Y_t^{\theta} = \mathcal{U}_{\theta}(X_0) - \int_{0}^{t} f(X_s,Y_s^{\theta}, \mathcal{Z}_{\theta}(s,X_s)) d s  + \int_{0}^{t} \mathcal{Z}_{\theta}(s,X_s)^{\top} \sigma(X_s) d W_s, \quad 0 \leq t \leq T.
\end{align}
\]</span></p>
<p>The method is called Deep “Backward” but in fact it simulates the process <span class="math inline">\(Y\)</span> as a forward process by trying to optimize over its initial parameter <span class="math inline">\(Y_0\)</span>.</p>
<p><span class="para-subtitle">Mathematical description of Deep BDP Solver : </span></p>
<p>The <strong>Deep BDP Solver</strong> is a solver which allows to approximate at every time-step <span class="math inline">\(t_i\)</span> the pair <span class="math inline">\((Y_{t_i},Z_{t_i})\)</span> by minimizing the local loss function, defined recursively by the Backward Euler Scheme :</p>
<p><span class="math display">\[
\begin{align}
\begin{cases}
Y_{t_{i+1}} &amp;= Y_{t_i} - f(X_{t_i},Y_{t_i},Z_{t_i}) \Delta_{t_i} + Z_{t_i}^{\top} \sigma(X_{t_i}) \Delta W_{t_i}, \quad i = n-1, \ldots, 0 \\
Y_{t_N} &amp;= g(X_{t_N}).
\end{cases}
\end{align}
\]</span> The method will either try to learn <span class="math inline">\((Y_{t_i},Z_{t_i})\)</span> at every <span class="math inline">\(i = n-1, \ldots,0\)</span> by defining multiple neural networks, one for <span class="math inline">\(Y\)</span> and one for other <span class="math inline">\(Z\)</span> or we could alternatively taking advantage of <a href="#eq-representationYZ" class="quarto-xref">Equation&nbsp;<span>1.12</span></a> using one neural network and use automatic differentiation.</p>
</div>


</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p><span class="math inline">\(\mathcal{S}_n\)</span> denotes the space of symmetric matrices over <span class="math inline">\(\mathbb{R}^{n \times n}\)</span><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>feedback refers to measurable function defined over time <span class="math inline">\(\times\)</span> state space .<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>We recall that a control process <span class="math inline">\(\alpha= (\alpha_s)_{t \leq s \leq T}\)</span> in the form <span class="math inline">\(\alpha_s = \mathrm{a}(s,X_s^{t,x})\)</span> is said to be Markovian.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../index.html" class="pagination-link" aria-label="Global informations">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Global informations</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../contents/DeepPDE/TP1.html" class="pagination-link" aria-label="Lab work n°1">
        <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Lab work n°1</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>