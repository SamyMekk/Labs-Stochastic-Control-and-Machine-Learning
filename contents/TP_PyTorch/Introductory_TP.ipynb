{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fe8af4b",
   "metadata": {},
   "source": [
    "<h1> <center> An introductory notebook to PyTorch module. </center ></h1>\n",
    "\n",
    "This notebook will cover the basics of PyTorch, a popular deep learning framework. We will go through the following topics:\n",
    "\n",
    "-  Installation of PyTorch\n",
    "- Tensors in PyTorch\n",
    "- Basic operations on Tensors\n",
    "- Autograd: Automatic differentiation\n",
    "- Building a simple neural network\n",
    "- Training the neural network\n",
    "- Evaluating the model\n",
    "- Saving and loading models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d73c12a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cec970e5",
   "metadata": {},
   "source": [
    "<h3> Setting PyTorch </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c70bbc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e823ba83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b1aa36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.9.1+cpu\n",
      "Device : cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samym\\AppData\\Local\\Temp\\ipykernel_10668\\1737830671.py:63: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | step   50 | loss 2.3549 | 1117 samples/s\n",
      "\n",
      "Epoch 1 done | avg loss 2.3294 | throughput 1065 samples/s \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# -------------------------\n",
    "# Device\n",
    "# -------------------------\n",
    "def pick_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "device = pick_device()\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"Device :\", device)\n",
    "if device.type == \"cuda\":\n",
    "    prop = torch.cuda.get_device_properties(0)\n",
    "    print(\"GPU    :\", prop.name, f\"({prop.total_memory/(1024**3):.2f} GB)\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# -------------------------\n",
    "# Synthetic data (no torchvision)\n",
    "# -------------------------\n",
    "# Tu peux augmenter N pour plus long, ou batch_size pour plus de charge GPU\n",
    "N = 200_000          # nombre d'exemples\n",
    "in_dim = 1024        # taille input\n",
    "num_classes = 10\n",
    "batch_size = 2048    # si OOM: 2048 -> 1024 -> 512\n",
    "epochs = 5\n",
    "\n",
    "# Données aléatoires\n",
    "X = torch.randn(N, in_dim)\n",
    "y = torch.randint(0, num_classes, (N,))\n",
    "ds = TensorDataset(X, y)\n",
    "loader = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=(device.type==\"cuda\"))\n",
    "\n",
    "# -------------------------\n",
    "# Simple FFN\n",
    "# -------------------------\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2048, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = MLP().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "\n",
    "use_amp = (device.type == \"cuda\")\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "# -------------------------\n",
    "# Train\n",
    "# -------------------------\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    t0 = time.time()\n",
    "    seen = 0\n",
    "    loss_sum = 0.0\n",
    "\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    for step, (xb, yb) in enumerate(loader, 1):\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        if use_amp:\n",
    "            with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "                logits = model(xb)\n",
    "                loss = criterion(logits, yb)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        bs = xb.size(0)\n",
    "        seen += bs\n",
    "        loss_sum += loss.item() * bs\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            dt = time.time() - t0\n",
    "            imgs_s = seen / max(dt, 1e-9)\n",
    "            msg = f\"Epoch {epoch} | step {step:4d} | loss {loss_sum/seen:.4f} | {imgs_s:.0f} samples/s\"\n",
    "            if device.type == \"cuda\":\n",
    "                peak = torch.cuda.max_memory_allocated() / (1024**2)\n",
    "                msg += f\" | peak VRAM {peak:.0f} MB\"\n",
    "            print(msg)\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    samples_s = seen / max(dt, 1e-9)\n",
    "    msg = f\"\\nEpoch {epoch} done | avg loss {loss_sum/seen:.4f} | throughput {samples_s:.0f} samples/s\"\n",
    "    if device.type == \"cuda\":\n",
    "        peak = torch.cuda.max_memory_allocated() / (1024**2)\n",
    "        msg += f\" | peak VRAM {peak:.0f} MB\"\n",
    "    print(msg, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ab3b23",
   "metadata": {},
   "source": [
    "<h3> Basic Operations on PyTorch </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f56ed3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version torch: 2.9.1+cpu\n",
      "a, b, c:\n",
      "tensor([1, 2, 3])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[-0.8073,  0.5935,  0.9673],\n",
      "        [-0.1903,  0.2044, -0.1103]])\n",
      "dtype, device, shape: torch.float32 cpu torch.Size([2, 3])\n",
      "b[0,1]: tensor(1)\n",
      "b slice: tensor([[1, 2],\n",
      "        [4, 5],\n",
      "        [7, 8]])\n",
      "view reshape: torch.Size([3, 4]) torch.Size([2, 6])\n",
      "unsqueeze/squeeze: torch.Size([1, 12]) torch.Size([12])\n",
      "flatten: torch.Size([12])\n",
      "permute: torch.Size([4, 2, 3])\n",
      "cat dim0: torch.Size([4, 3])\n",
      "stack dim0: torch.Size([2, 2, 3])\n",
      "u + 1: tensor([2., 3., 4.])\n",
      "broadcast add: tensor([[2., 3., 4.],\n",
      "        [3., 4., 5.]])\n",
      "matmul: tensor([[ 0.4739,  0.4555],\n",
      "        [-0.9184, -2.1857],\n",
      "        [-0.5198,  3.8290]]) shape: torch.Size([3, 2])\n",
      "sum, mean, min, max: -3.723116636276245 -0.18615582585334778 -2.5148234367370605 1.3412643671035767\n",
      "argmax dim0: tensor([2, 1, 2, 0])\n",
      "mask sum positive: 9\n",
      "masked select: tensor([0.4465, 0.5806, 1.2030, 0.7499, 0.1512, 1.3413, 0.2629, 0.0161, 0.9788])\n",
      "in-place add_: tensor([2., 3., 4.])\n",
      "grad: tensor([2., 4., 6.])\n",
      "numpy: [1. 2. 3.] <class 'numpy.ndarray'>\n",
      "astype (float->int): tensor([1, 2], dtype=torch.int32)\n",
      "clamp: tensor([0.0000, 0.2000, 3.0000, 3.0000])\n",
      "round: tensor([-2.,  0.,  4.,  4.])\n",
      "unique: tensor([-1.5000,  0.2000,  3.7000])\n",
      "sort: tensor([-1.5000,  0.2000,  3.7000,  3.7000])\n",
      "einsum (trace): tensor(-0.3977)\n",
      "Exemple résumé OK\n"
     ]
    }
   ],
   "source": [
    "print(\"Version torch:\", torch.__version__)\n",
    "\n",
    "# Création\n",
    "a = torch.tensor([1, 2, 3])                    # à partir d'une liste (dtype inféré)\n",
    "b = torch.arange(0, 9).reshape(3, 3)           # arange + reshape\n",
    "c = torch.randn(2, 3)                          # aléatoire normale\n",
    "zeros = torch.zeros(2, 2)\n",
    "ones = torch.ones(2, 2)\n",
    "eye = torch.eye(3)\n",
    "from_numpy = torch.from_numpy(np.array([10, 20, 30]))  # depuis numpy (même mémoire si CPU)\n",
    "\n",
    "print(\"a, b, c:\", a, b, c, sep=\"\\n\")\n",
    "\n",
    "# Propriétés\n",
    "print(\"dtype, device, shape:\", c.dtype, c.device, c.shape)\n",
    "\n",
    "# Indexing & slicing\n",
    "print(\"b[0,1]:\", b[0, 1])\n",
    "print(\"b slice:\", b[:, 1:3])\n",
    "\n",
    "# Reshape / view / flatten / squeeze / unsqueeze\n",
    "x = torch.arange(12)\n",
    "print(\"view reshape:\", x.view(3, 4).shape, x.reshape(2, 6).shape)\n",
    "print(\"unsqueeze/squeeze:\", x.unsqueeze(0).shape, x.unsqueeze(0).squeeze().shape)\n",
    "print(\"flatten:\", x.flatten().shape)\n",
    "\n",
    "# Transpose / permute\n",
    "m = torch.randn(2, 3, 4)\n",
    "print(\"permute:\", m.permute(2, 0, 1).shape)\n",
    "\n",
    "# Concat / stack\n",
    "p1 = torch.randn(2, 3)\n",
    "p2 = torch.randn(2, 3)\n",
    "print(\"cat dim0:\", torch.cat([p1, p2], dim=0).shape)\n",
    "print(\"stack dim0:\", torch.stack([p1, p2], dim=0).shape)\n",
    "\n",
    "# Arithmétique (élément-wise) et broadcasting\n",
    "u = torch.tensor([1.0, 2.0, 3.0])\n",
    "v = torch.tensor([[1.0], [2.0]])\n",
    "print(\"u + 1:\", u + 1)\n",
    "print(\"broadcast add:\", u + v)   # broadcasting\n",
    "\n",
    "# Matmul / @\n",
    "A = torch.randn(3, 4)\n",
    "B = torch.randn(4, 2)\n",
    "print(\"matmul:\", A @ B, \"shape:\", (A @ B).shape)\n",
    "\n",
    "# Reductions\n",
    "t = torch.randn(5, 4)\n",
    "print(\"sum, mean, min, max:\", t.sum().item(), t.mean().item(), t.min().item(), t.max().item())\n",
    "print(\"argmax dim0:\", t.argmax(dim=0))\n",
    "\n",
    "# Comparaisons & masque logique\n",
    "mask = t > 0\n",
    "print(\"mask sum positive:\", mask.sum().item())\n",
    "print(\"masked select:\", t[t > 0])\n",
    "\n",
    "# In-place ops (attention aux gradients)\n",
    "z = torch.tensor([1.0, 2.0, 3.0])\n",
    "z.add_(1.0)   # modifie z\n",
    "print(\"in-place add_:\", z)\n",
    "\n",
    "# Clone / detach / requires_grad / backward\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "y = (x ** 2).sum()\n",
    "y.backward()            # dy/dx = 2*x\n",
    "print(\"grad:\", x.grad)\n",
    "\n",
    "xd = x.detach().clone() # détaché du graphe\n",
    "\n",
    "# Conversion vers numpy (doit être sur CPU)\n",
    "arr = x.cpu().detach().numpy()\n",
    "print(\"numpy:\", arr, type(arr))\n",
    "\n",
    "# Déplacement device / dtype conversion\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA disponible, envoi sur GPU\")\n",
    "    A_cuda = A.to('cuda')\n",
    "    A_cpu = A_cuda.to('cpu')\n",
    "\n",
    "print(\"astype (float->int):\", torch.tensor([1.2, 2.8]).to(torch.int))\n",
    "\n",
    "# Utilitaires: clamp, round, sort, unique\n",
    "vals = torch.tensor([-1.5, 0.2, 3.7, 3.7])\n",
    "print(\"clamp:\", vals.clamp(0, 3))\n",
    "print(\"round:\", vals.round())\n",
    "print(\"unique:\", vals.unique())\n",
    "print(\"sort:\", vals.sort().values)\n",
    "\n",
    "# Autres utiles: einsum, torch.nn.functional ops\n",
    "print(\"einsum (trace):\", torch.einsum('ii->', torch.randn(3, 3)))\n",
    "\n",
    "# Remise à zéro des gradients\n",
    "x.grad.zero_()\n",
    "\n",
    "# Exemple rapide résumé\n",
    "print(\"Exemple résumé OK\")\n",
    "# ...existing code..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
